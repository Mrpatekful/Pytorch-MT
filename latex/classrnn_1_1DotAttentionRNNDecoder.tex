\hypertarget{classrnn_1_1DotAttentionRNNDecoder}{}\section{rnn.\+Dot\+Attention\+R\+N\+N\+Decoder Class Reference}
\label{classrnn_1_1DotAttentionRNNDecoder}\index{rnn.\+Dot\+Attention\+R\+N\+N\+Decoder@{rnn.\+Dot\+Attention\+R\+N\+N\+Decoder}}


Inheritance diagram for rnn.\+Dot\+Attention\+R\+N\+N\+Decoder\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=238pt]{classrnn_1_1DotAttentionRNNDecoder__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for rnn.\+Dot\+Attention\+R\+N\+N\+Decoder\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=238pt]{classrnn_1_1DotAttentionRNNDecoder__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
def {\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+}\hypertarget{classrnn_1_1DotAttentionRNNDecoder_a6eea546565f762ee83ff51c28e1645d4}{}\label{classrnn_1_1DotAttentionRNNDecoder_a6eea546565f762ee83ff51c28e1645d4}

\item 
def \hyperlink{classrnn_1_1DotAttentionRNNDecoder_a0bbac7d4dc05b35c0873c6d0074d6499}{init\+\_\+parameters} (self)
\end{DoxyCompactItemize}
\subsection*{Static Public Attributes}
\begin{DoxyCompactItemize}
\item 
{\bfseries interface} = R\+N\+N\+Decoder.\+interface\hypertarget{classrnn_1_1DotAttentionRNNDecoder_a8f77e3e523eaf8d375280e22818a72e0}{}\label{classrnn_1_1DotAttentionRNNDecoder_a8f77e3e523eaf8d375280e22818a72e0}

\item 
bool {\bfseries abstract} = False\hypertarget{classrnn_1_1DotAttentionRNNDecoder_a6b36fac841800f586bbfa7670003d669}{}\label{classrnn_1_1DotAttentionRNNDecoder_a6b36fac841800f586bbfa7670003d669}

\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\begin{DoxyVerb}Global attention mechanism for the recurrent decoder module. The algorithm is a specific case
of Luong style attention, where the scoring is based off of only the dot product of the
encoder and decoder states.
\end{DoxyVerb}
 

\subsection{Member Function Documentation}
\index{rnn\+::\+Dot\+Attention\+R\+N\+N\+Decoder@{rnn\+::\+Dot\+Attention\+R\+N\+N\+Decoder}!init\+\_\+parameters@{init\+\_\+parameters}}
\index{init\+\_\+parameters@{init\+\_\+parameters}!rnn\+::\+Dot\+Attention\+R\+N\+N\+Decoder@{rnn\+::\+Dot\+Attention\+R\+N\+N\+Decoder}}
\subsubsection[{\texorpdfstring{init\+\_\+parameters(self)}{init_parameters(self)}}]{\setlength{\rightskip}{0pt plus 5cm}def rnn.\+Dot\+Attention\+R\+N\+N\+Decoder.\+init\+\_\+parameters (
\begin{DoxyParamCaption}
\item[{}]{self, }
\item[{}]{Decoder}
\end{DoxyParamCaption}
)}\hypertarget{classrnn_1_1DotAttentionRNNDecoder_a0bbac7d4dc05b35c0873c6d0074d6499}{}\label{classrnn_1_1DotAttentionRNNDecoder_a0bbac7d4dc05b35c0873c6d0074d6499}
\begin{DoxyVerb}Initializes the parameters for the decoder.
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/components/decoders/rnn.\+py\end{DoxyCompactItemize}
