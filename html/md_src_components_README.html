<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>PyTorch-MT: Components</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">PyTorch-MT
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Components </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Components are the main building blocks of the models. In particular, the sequence-to-sequence type models are well-suited for these modular elements. In the current state of the API, there are two distinct versions of the components, encoders and decoders. Each of these have 3 different methods:</p>
<ol type="1">
<li>Recurrent</li>
<li>Convolutional</li>
<li>Quasi-Recurrent</li>
</ol>
<div class="image">
<img src="https://github.com/Mrpatekful/nmt-BMEVIAUAL01/blob/master/data/img/components.png"  alt="component visualization"/>
</div>
<hr/>
<h2>Encoders</h2>
<h3>Recurrent</h3>
<ol type="1">
<li>Unidirectional encoder</li>
<li>Bidirectional encoder</li>
</ol>
<p>Unidirectional type encoders could be considered as the regular recurrent units, which may yield different methods for calculations. The currently implemented features are the LSTM-type units and GRUs. The problem with these type of architectures, is the ability to preserve references in long sequences. Even the LSTMs and GRUs can't seem to resolve dependencies in longer, 40-50 unit length sequences. As a solution Bidirectional encoders start their operations from the end of the sentence, going 'backward' in time, as well as from the start of the sequence. This way there are 2 hidden states, one for each direction, which will then be concatenated, and fed to the upcoming layer. This method shortens the path between dependencies, and performs considerably better in numerous tasks.</p>
<h3>Convolutional</h3>
<p><em>COMING SOON</em></p>
<h3>Quasi-Recurrent</h3>
<p><em>COMING SOON</em></p>
<hr/>
<h2>Decoders</h2>
<h3>Recurrent</h3>
<ol type="1">
<li>Regular decoder</li>
<li>Attentional decoder<ol type="a">
<li>Bahdanau-style</li>
<li>Luong-style<ol type="i">
<li>Dot Attention Decoder</li>
<li>General Attention Decoder</li>
<li>Concat Attention Decoder</li>
</ol>
</li>
</ol>
</li>
</ol>
<h4>Regular</h4>
<p>Similarly to the encoders, the basic recurrent decoders also operate with an LSTM or GRU. The encoder provides the starting hidden state for the component, that contains the encoded latent representation of the source language. The decoder then starts to unfold this hidden state by predicting the first word of the target sentence, which will be then fed to the decoder at the next time step. This phase goes until the decoder predicts an &lt;EOS&gt; token. Although this simple method is the fastest, there are other techniques, which provide much better performance.</p>
<h4>Bahdanau-style Attention Decoder</h4>
<p>Considering the method of translation from a human viewpoint, the encoder-decoder method of machine translation may not be a very intuitive approach, since when the decoder tries to predict the most probable word at the first position, it takes the whole encoded sentence into account. It would be much more natural, if the decoder would only consider those parts of the source sentence, which highly correlate to the currently decoded word of the target sentence. <a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> introduces a method for this approach, that is called attention, which is an existing techniques in image related machine learning tasks, but has not been applied to natural language processing yet.</p>
<p>The main idea is to integrate another layer between the decoder and encoder, which will operate this mechanism. At each decoding step this layer calculates a weight distribution over the outputs of the encoder at each encoding time step. The new encoded latent state will come from the linear combination of the encoder hidden states, with their corresponding weights.</p>
<div class="image">
<img src="https://github.com/Mrpatekful/nmt-BMEVIAUAL01/blob/master/data/img/attention.png"  alt="attention visualization"/>
</div>
<p>Although the core concept of attention is the same, there are different methods for calculating the weights for the encoder outputs. The already mentioned Bahdanau-style method uses a trainable layer, which takes the concatenation of the investigated encoder state and the decoder state the at the previous time step. The output of this operation is a single scalar value (or a vector of values in case of batched calculations), that will be the weight for the used encoder state. After each of the encoder output states have been weighted, the recurrent layer receives the weighted sum of these vectors.</p>
<h4>Luong-style Attention Decoder</h4>
<p>Another approach has been introduced by <a href="https://arxiv.org/abs/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a>, which alters the order of weight calculation, and defines several alternative techniques for the scoring mechanism. Compared to the Bahdanau method <code>recurrent(score(h_t-1), i_t)</code> where i_t is the output of the previous decoding time step, and h_t-1 is the hidden state of the previous time step, the Luong method calculates <code>score(recurrent(h_t-1, i_t))</code>. The scoring of hidden state with respect to the encoder outputs, happens at the t-th time step, which will be used by a final output layer, that projects the hidden state to the vocabulary, with a softmax activation.</p>
<p>As mentioned above, Luong introduced 2 new methods for weight calculation (score function) additional to the method used in Bahdanau's work.</p>
<ol type="1">
<li><em>Dot Attention Decoder</em></li>
</ol>
<p>The simplest and fastest scoring function, which according to my experience, helps the convergence of the model, better than any other scoring methods. The weight simply comes from the dot product of the encoder state and the hidden state. </p><pre class="fragment">h_d * h_eT
</pre><ol type="1">
<li><em>General Attention Decoder</em></li>
</ol>
<p>This method uses a trainable layer similar to the concatenative methods, but instead of concatenation, it takes the dot product of the weight layer, with the encoder output state, and then the dot product with the decoder hidden state. </p><pre class="fragment">h_d * (W_a * h_eT)
</pre><p>The positive impact of this method compared to the simple dot product, is the constrain of creating a good attention weight distribution over the encoder output states is the responsibility of the attention weight layer, instead of the encoder and decoder recurrent layers.</p>
<ol type="1">
<li><em>Concat Attention Decoder</em></li>
</ol>
<p>This method is the same as the one used in Bahdanau's experiments, which takes the concatenation of the decoder hidden state and encoder output state, with a dedicated attention weight layer. </p><pre class="fragment">v_t * tanh(W_a * [h_d ; h_e])
</pre><h3>Convolutional</h3>
<p><em>COMING SOON</em></p>
<h3>Quasi-Recurrent</h3>
<p><em>COMING SOON</em> </p>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
